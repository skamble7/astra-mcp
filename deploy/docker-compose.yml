services:
  mcp-git-repo-snapshot:
    build:
      context: ../servers/git-repo-snapshot
      dockerfile: Dockerfile
      args:
        EXTRAS: "sse"
    image: astra/mcp-git-repo-snapshot:local
    container_name: mcp-git-repo-snapshot
    restart: unless-stopped
    environment:
      MCP_TRANSPORT: streamable-http
      MCP_PORT: ${GIT_SNAPSHOT_PORT:-8000}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
    ports:
      - "${GIT_SNAPSHOT_PORT:-8000}:8000"
    volumes:
      - ${WORKSPACE_HOST_DIR:-../data/workspace}:/workspace

  mcp-cobol-parser:
    build:
      context: ../servers/mcp-cobol-parser
      dockerfile: Dockerfile
    image: astra/mcp-cobol-parser:local
    container_name: mcp-cobol-parser
    restart: unless-stopped
    environment:
      # MCP runner config
      MCP_TRANSPORT: streamable-http
      MCP_PORT: ${COBOL_PARSER_PORT:-8765}
      MCP_MOUNT_PATH: /mcp

      # service config
      PAGE_SIZE: 100
      MAX_PAGE_SIZE: 500
      WORKERS: 8
      CACHE_DIR: /app/.cache
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
    ports:
      - "${COBOL_PARSER_PORT:-8765}:8765"
    volumes:
      - ${WORKSPACE_HOST_DIR:-../data/workspace}:/workspace

  mcp-mermaid-diagrammer:
    build:
      context: ../servers/mcp-mermaid-diagrammer
      dockerfile: Dockerfile
    image: astra/mcp-mermaid-diagrammer:local
    container_name: mcp-mermaid-diagrammer
    restart: unless-stopped
    environment:
      MCP_TRANSPORT: streamable-http
      MCP_PORT: ${MERMAID_DIAGRAMMER_PORT:-8001}
      MCP_MOUNT_PATH: /mcp
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      ENABLE_REAL_LLM: "false"
      LLM_PROVIDER: OpenAI
      LLM_MODEL: gpt-4o-mini
      OPENAI_API_KEY: <OPENAI_API_KEY>
    ports:
      - "${MERMAID_DIAGRAMMER_PORT:-8001}:8001"
  
  mcp-workspace-doc-generator:
    build:
      context: ../servers/workspace-doc-generator
      dockerfile: Dockerfile
    image: astra/mcp-workspace-doc-generator:local
    container_name: mcp-workspace-doc-generator
    restart: unless-stopped
    depends_on:
      - garage
    environment:
      # --- MCP Transport ---
      MCP_TRANSPORT: streamable-http
      MCP_PORT: ${WORKSPACE_DOC_PORT:-8002}
      MCP_MOUNT_PATH: /mcp

      # --- Logging ---
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      SERVICE_NAME: mcp.workspace.doc.generator

      # --- LLM (OpenAI) ---
      ENABLE_REAL_LLM: "true"     # set "false" for offline mode
      LLM_PROVIDER: OpenAI
      LLM_MODEL: gpt-4o-mini
      LLM_TEMPERATURE: "0.2"
      LLM_MAX_TOKENS: "10000"
      OPENAI_API_KEY: <OPENAI_API_KEY>

      # --- Services ---
      # Artifact service is in a separate compose; talk to the host-published port
      ARTIFACT_SERVICE_URL: http://host.docker.internal:9020

      # --- Output directory inside the container ---
      OUTPUT_DIR: /out

      # --- Garage / S3 ---
      # Use the internal service name so it resolves inside the compose network.
      S3_ENDPOINT_URL: http://garage:3900
      S3_REGION: garage
      S3_ACCESS_KEY: GK9811538bf0c4e746d0f0acd4
      S3_SECRET_KEY: 0d5e17cb76bc132c05afdea4870db8ee44116c88e84b776ec419dc195ae1042e
      S3_BUCKET: astra-docs
      S3_PREFIX: workspace-docs

      # Pre-signed URL controls (Option B)
      S3_FORCE_SIGNED: "true"                # always return a pre-signed URL
      S3_PRESIGN_TTL_SECONDS: "604800"       # 7 days
      # Replace the internal garage hostname in the signed URL so it works from the host:
      S3_PRESIGN_BASE_URL: http://localhost:3900

      # (Public website base is unused when S3_FORCE_SIGNED=true; kept here for clarity)
      S3_PUBLIC_BASE_URL: ""
      S3_PUBLIC_READ: "true"
    ports:
      - "${WORKSPACE_DOC_PORT:-8002}:8002"
    volumes:
      # Persist generated workspace markdown summaries
      - ./data/output/workspace-docs:/out
      # Optional local-fallback context (if you ever drop artifacts.json for a workspace)
      - ${WORKSPACE_HOST_DIR:-../data/workspace}:/workspace
    extra_hosts:
      # Keep this for host-only services like the artifact service.
      - "host.docker.internal:host-gateway"
  
  garage:
    image: dxflrs/garage:v2.1.0
    container_name: garage
    restart: unless-stopped
    ports:
      - "3900:3900"   # S3 API
      - "3901:3901"   # RPC
      - "3902:3902"   # Static web (optional)
      - "3903:3903"   # Admin API
    volumes:
      - ./garage/garage.toml:/etc/garage.toml:ro
      - ./garage/meta:/var/lib/garage/meta
      - ./garage/data:/var/lib/garage/data
    environment:
      - RUST_LOG=garage=info

volumes:
  garage-meta: