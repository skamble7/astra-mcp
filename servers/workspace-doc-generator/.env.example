# --- MCP Transport ---
MCP_TRANSPORT=stdio
MCP_SSE_HOST=0.0.0.0
MCP_SSE_PORT=8895

# --- Services ---
ARTIFACT_SERVICE_URL=http://host.docker.internal:9020

# --- LLM (OpenAI) ---
ENABLE_REAL_LLM=true
LLM_PROVIDER=OpenAI
LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.2
LLM_MAX_TOKENS=1600
# Inject at runtime; don't commit real keys:
OPENAI_API_KEY=<OPENAI_API_KEY>

# --- Output (local fallback) ---
OUTPUT_DIR=/tmp/mcp-workspace-docs

# --- Logging ---
SERVICE_NAME=mcp.workspace.doc.generator
LOG_LEVEL=INFO

# --- Garage / S3 ---
S3_ENDPOINT_URL=http://host.docker.internal:3900
S3_REGION=garage
S3_ACCESS_KEY=astra-docs-key
S3_SECRET_KEY=0d5e17cb76bc132c05afdea4870db8ee44116c88e84b776ec419dc195ae1042e
S3_BUCKET=astra-docs                  # <-- matches `garage bucket create astra-docs`
S3_PREFIX=workspace-docs
S3_PUBLIC_BASE_URL=http://localhost:3902/astra-docs  # <-- includes hyphen, points at bucket root
S3_PUBLIC_READ=true

# --- LLM chunking (optional) ---
LLM_CHUNK_TARGET_BYTES=110000
LLM_CHUNK_MAX_ITEMS=12